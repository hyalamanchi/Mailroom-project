# CP2000 Mail Room Automation Pipeline

> Automated IRS CP2000 document processing and case management system

![Python Version](https://img.shields.io/badge/python-3.9+-blue.svg)
![Status](https://img.shields.io/badge/status-production-success.svg)
![License](https://img.shields.io/badge/license-Proprietary-red.svg)

## ğŸ“‹ Overview

An intelligent automation pipeline for processing IRS CP2000 (Underreported Income Notice) letters. This system extracts taxpayer information using OCR, matches cases to Logiqs CRM, organizes documents automatically, and creates review tasks for the tax resolution team.

**Key Benefits:**
- â±ï¸ **Time Savings:** 4.5 hours per day (from 5-6 hours to 20-25 minutes)
- ğŸ¯ **Match Rate:** 83-87% automatic case matching
- ğŸ“Š **Processing:** 100-150 files per day
- âœ… **Accuracy:** Enhanced OCR with validation

## ğŸš€ Features

### Core Capabilities
- **Automated OCR Extraction** - Extracts SSN, taxpayer names, tax years, notice dates
- **Smart Case Matching** - Fuzzy matching with name variations and SSN corrections
- **Google Drive Integration** - Automatic file organization and movement
- **Logiqs CRM Integration** - Document upload with automatic task creation
- **Intelligent Routing** - Matched cases â†’ auto-upload, Unmatched â†’ manual review
- **Comprehensive Reporting** - Excel and JSON reports for team coordination

### Workflow Automation
```
Input Folders â†’ Extract Data â†’ Match Cases â†’ Organize Files
                                            â†“
                              Matched â†’ Auto Upload to Logiqs
                              Unmatched â†’ Manual Review Queue
```

## ğŸ“‚ Project Structure

```
CP2000_Pipeline/
â”œâ”€â”€ daily_pipeline_orchestrator.py    # Main automation script
â”œâ”€â”€ production_extractor.py           # OCR and data extraction
â”œâ”€â”€ logics_case_search.py            # Logiqs API integration
â”œâ”€â”€ upload_to_logiqs.py               # Document upload with tasks
â”œâ”€â”€ enhanced_case_matcher.py          # Advanced matching strategies
â”œâ”€â”€ generate_upload_list.py           # Naming convention generator
â”œâ”€â”€ hundred_percent_accuracy_extractor.py  # Core OCR engine
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ DAILY_WORKFLOW_GUIDE.md          # Complete workflow documentation
â””â”€â”€ README.md                         # Technical documentation
```

## âš™ï¸ Installation

### Prerequisites
- Python 3.9 or higher
- Google Cloud Project with Drive API enabled
- Logiqs CRM API access
- Tesseract OCR installed

### Setup Steps

1. **Clone the repository**
```bash
git clone https://github.com/TaxReliefAdvocates/CP2000_Pipeline.git
cd CP2000_Pipeline
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Configure Google Drive API**
   - Place `credentials.json` in the project root
   - Run authentication on first use (creates `token.pickle`)

4. **Configure environment variables**
```bash
# Create .env file
LOGIQS_API_KEY=your_api_key_here
LOGIQS_SECRET_TOKEN=your_secret_token_here
```

## ğŸ¯ Usage

### Daily Workflow

**Step 1: Process New Files (5-10 minutes)**
```bash
python3 daily_pipeline_orchestrator.py
```
- Downloads files from Google Drive input folders
- Extracts data using OCR
- Matches to Logiqs CRM
- Organizes into matched/unmatched folders
- Generates daily reports

**Step 2: Upload Matched Cases (10-15 minutes)**
```bash
python3 upload_to_logiqs.py
```
- Uploads matched documents to Logiqs
- Creates review tasks automatically
- Generates upload reports

**Step 3: Review Unmatched Cases**
- Open `DAILY_REPORTS/UNMATCHED/*.xlsx`
- Process manually as needed

### Test Mode

Test with 5 files before production:
```bash
python3 daily_pipeline_orchestrator.py --test
```
- Processes only 5 files
- No files moved in Google Drive
- Safe for testing

## ğŸ“Š Expected Results

**Daily Processing (150 files):**
- âœ… Matched: 125 files (83%) â†’ Auto-uploaded
- âš ï¸ Unmatched: 25 files (17%) â†’ Manual review
- â±ï¸ Total Time: 20-25 minutes
- ğŸ’¾ Time Saved: 4.5 hours per day

## ğŸ”§ Configuration

### Google Drive Folders
Configure folder IDs in `daily_pipeline_orchestrator.py`:
```python
self.folders = {
    'input_cp2000': 'YOUR_FOLDER_ID',
    'input_newbatch': 'YOUR_FOLDER_ID',
    'output_matched': 'YOUR_FOLDER_ID',
    'output_unmatched': 'YOUR_FOLDER_ID'
}
```

### API Configuration
Logiqs API endpoints are configured in `logics_case_search.py` and `upload_to_logiqs.py`.

## ğŸ“ˆ Performance Metrics

| Metric | Value |
|--------|-------|
| Processing Speed | 100-150 files in 5-10 min |
| Match Rate | 83-87% |
| Upload Success | >95% |
| Time Savings | 4.5 hours/day |
| Files per Second | 0.3-0.5 |

## ğŸ› ï¸ Technical Stack

- **Language:** Python 3.9+
- **OCR:** Tesseract, PyMuPDF, OpenCV
- **APIs:** Google Drive API, Logiqs CRM API
- **Data Processing:** Pandas, NumPy
- **Authentication:** OAuth 2.0, Basic Auth

## ğŸ“ Documentation

- [DAILY_WORKFLOW_GUIDE.md](DAILY_WORKFLOW_GUIDE.md) - Complete daily workflow
- [TASK_CREATION_SUCCESS.md](TASK_CREATION_SUCCESS.md) - Task API integration
- [FOLDER_STRUCTURE_VISUAL.txt](FOLDER_STRUCTURE_VISUAL.txt) - Folder organization
- [README.md](README.md) - Technical documentation

## ğŸ”’ Security Notes

- API credentials stored in `.env` (not tracked in git)
- Google OAuth tokens in `token.pickle` (not tracked in git)
- All sensitive data excluded via `.gitignore`

## ğŸ¤ Contributing

This is a proprietary project for Tax Relief Advocates. Internal contributions only.

## ğŸ“ Support

**Author:** Hemalatha Yalamanchi  
**Email:** [Your Email]  
**Organization:** Tax Relief Advocates

## ğŸ“„ License

Proprietary - All Rights Reserved  
Â© 2025 Tax Relief Advocates

## ğŸ‰ Achievements

- âœ… 100% automated workflow
- âœ… 83-87% match rate
- âœ… 4.5 hours saved daily
- âœ… Production-ready system
- âœ… Comprehensive error handling
- âœ… Full audit trail

---

**Built with â¤ï¸ by Hemalatha Yalamanchi for Tax Relief Advocates**

